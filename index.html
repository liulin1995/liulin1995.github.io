<!DOCTYPE html>
<html>
<head><meta name="generator" content="Hexo 3.9.0">
  <meta charset="utf-8">
  
  <title>LZW</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta property="og:type" content="website">
<meta property="og:title" content="LZW">
<meta property="og:url" content="http://yoursite.com/index.html">
<meta property="og:site_name" content="LZW">
<meta property="og:locale" content="default">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="LZW">
  
    <link rel="alternate" href="/atom.xml" title="LZW" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    
  
  <link rel="stylesheet" href="/css/style.css">
  

</head>
</html>
<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    
    <div id="header-inner" class="inner">
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="搜索"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://yoursite.com"></form>
      </div>
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">首页</a>
        
          <a class="main-nav-link" href="/archives">归档</a>
        
          <a class="main-nav-link" href="/about">关于</a>
        
          <a class="main-nav-link" href="/categories">类别</a>
        
      </nav>
      
    </div>
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">LZW</a>
      </h1>
      
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main">
  
    <article id="post-Cyclical-Learning-Rates-for-Training-Neural-Networks" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2019/07/02/Cyclical-Learning-Rates-for-Training-Neural-Networks/" class="article-date">
  <time datetime="2019-07-02T14:12:09.000Z" itemprop="datePublished">2019-07-02</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/deep-learning/">deep learning</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2019/07/02/Cyclical-Learning-Rates-for-Training-Neural-Networks/">Cyclical Learning Rates for Training Neural Networks</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <!-- Table of Contents -->
        
        <h2 id="paper-details"><a href="#paper-details" class="headerlink" title="paper details"></a>paper details</h2><p>深度学习中有一个常识是，学习率在训练的过程中需要逐渐减小。但是这篇文章却给出了一个让人惊讶的事实，就是训练过程中的学习率如果是多变（rise and fall）的是有益于训练的。因此作者建议学习率在一个范围内周期变化，而不是将其设置为固定值。</p>
<p>Cyclical Learning Rates来源于这么一个观察：学习率的增加虽然会带来短期的副作用但是长期来看是有益的。因此这种观察引出了让学习率在一定范围内变化而不是采用逐步固定或指数递减值的想法。即设置一个最大和最小的边界，然后学习率在里面循环变化。如下图的 triangular learning rate policy：</p>
<p><img src="/images/assets/1557733855040.png" alt="1557733855040"></p>
<p>CLR能够发挥作用的一个直观理解是：最小化loss的困难在于如何逃离saddle点而不是在于差的局部最小值。在saddle 点的附近，梯度都很小因此学习的过程缓慢，因此通过增加学习率可以更快地走出saddle点区域。经验上的理由为什么CLR能够work是这样的：最佳的学习率可能在min-max boundaries之间，在最佳的学习率附近会被用于进行训练。（其他会被用于脱离saddle点。。。）。</p>
<p>除了上面显示的trangular learning rate policy,还有以下两种:</p>
<ol>
<li><p>triangular2, 和triangular差不多，差别在于每一个cycle之后lr会减半。</p>
</li>
<li><p>exp_range，boundary的值会以一个指数因子衰减。</p>
</li>
</ol>
<p><img src="/images/assets/1557737380100.png" alt="1557737380100"></p>
<p><img src="/images/assets/1557737358780.png" alt="1557737358780"></p>
<p>里面还讲了如何去估计一个cycle len的方法：</p>
<p>stepsize最好是2-10倍的每个epoch的迭代次数。对于CIFAR10来说，stepsize=8也就比stepsize=2效果好上一点点。</p>
<p>此外还讲了如何估计一个合理的min和max boundary</p>
<p>第一个方法就是：“LR range test”,模型先跑几个epoch，然后让lr从一个很小值增加到很大的值。然后画出accuracy versus learning rate.如下图：</p>
<p><img src="/images/assets/1557735295110.png" alt="1557735295110"></p>
<p>注意图中的accuracy开始增加和accuracy开始变缓的时间段(或者accuracy开始下降)的地方。 这两个地方是bound是的一个好的选择。即base_lr是第一个值，而max_lr是第二个值。或者说可以用一个经验，将base_lr设置为1/3或1/4的max_lr. <strong>论文中作者选了base_lr = 0.001,而max_lr = 0.006</strong></p>
<p>另外一个选择bound是的方法式画出loss versus learning rate的图，如下：</p>
<p><img src="/images/assets/1557735640796.png" alt="1557735640796"></p>
<p>这张图中最适合的lr是哪里？不是在最低点，因为在最低点的lr已经有点大了。我们需要的是一个点更aggressive，所以我们能够train很快。即那个点loss下降是<strong>最快</strong>的</p>
<h2 id="实验过程"><a href="#实验过程" class="headerlink" title="实验过程"></a>实验过程</h2><p>做kaggle比赛的时候，clr的base_lr和max_lr设置反了，特别是在开始的一个stepsize里面，速度非常快，很容易就达到了一个很好的acc ，但是过了这个stepsize，acc就不断下降。一开始举得clclr的问题，后来突然发现是我输入的参数错误。有鉴于它收敛非常快，我觉得还是要借鉴下，发现lr的变化是这样的：</p>
<p><img src="/images/assets/1557732898573.png" alt="1557732898573"></p>
<p>和clr差了一个stepsize。这个和SGDR很相似，准备用这个试试。</p>
<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><p><a href="https://arxiv.org/pdf/1506.01186.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1506.01186.pdf</a></p>
<p><a href="https://sgugger.github.io/how-do-you-find-a-good-learning-rate.html#how-do-you-find-a-good-learning-rate" target="_blank" rel="noopener">https://sgugger.github.io/how-do-you-find-a-good-learning-rate.html#how-do-you-find-a-good-learning-rate</a></p>
<p><a href="https://towardsdatascience.com/estimating-optimal-learning-rate-for-a-deep-neural-network-ce32f2556ce0" target="_blank" rel="noopener">https://towardsdatascience.com/estimating-optimal-learning-rate-for-a-deep-neural-network-ce32f2556ce0</a></p>
<p><a href="https://www.paperweekly.site/papers/notes/598" target="_blank" rel="noopener">https://www.paperweekly.site/papers/notes/598</a></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2019/07/02/Cyclical-Learning-Rates-for-Training-Neural-Networks/" data-id="cjxlw76zw00005gul1zfyjkfw" class="article-share-link">分享</a>
      
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Cyclical-LR/">Cyclical LR</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/pytorch/">pytorch</a></li></ul>

    </footer>
  </div>
  
</article>
 


  
    <article id="post-TorchVision-Image-Transforms" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2019/07/02/TorchVision-Image-Transforms/" class="article-date">
  <time datetime="2019-07-02T14:09:59.000Z" itemprop="datePublished">2019-07-02</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/deep-learning/">deep learning</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2019/07/02/TorchVision-Image-Transforms/">TorchVison Image Transforms</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <!-- Table of Contents -->
        
        <p>transforms主要是图像transform, 它们可以通过使用Compose来链接起来。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">transforms.Compose([</span><br><span class="line">  transforms.CenterCrop(<span class="number">10</span>),</span><br><span class="line">  transforms.ToTensor()</span><br><span class="line">])</span><br></pre></td></tr></table></figure>

<h2 id="Transforms-on-PIL-Image"><a href="#Transforms-on-PIL-Image" class="headerlink" title="Transforms on PIL Image"></a>Transforms on PIL Image</h2><h4 id="torchvision-transforms-CenterCrop-size"><a href="#torchvision-transforms-CenterCrop-size" class="headerlink" title="torchvision.transforms.CenterCrop(size):"></a><code>torchvision.transforms.CenterCrop</code>(<em>size</em>):</h4><p>对给定的PIL image在中心处裁剪。</p>
<p>参数为：<strong>size</strong>, int or sequence. 如果是一个sequence，比如（h,w）会裁剪一个h*w大小的图片。</p>
<p>如果是int，那么会裁剪大小为（size，size）的图像</p>
<h4 id="torchvision-transforms-FiveCrop-size"><a href="#torchvision-transforms-FiveCrop-size" class="headerlink" title="torchvision.transforms.FiveCrop(size)"></a><code>torchvision.transforms.FiveCrop</code>(<em>size</em>)</h4><p>对给定的PIL image的四个角和中心进行裁剪</p>
<p>其他同上。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>transform = Compose([</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>   FiveCrop(size), <span class="comment"># this is a list of PIL Images</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>   Lambda(<span class="keyword">lambda</span> crops: torch.stack([ToTensor()(crop) <span class="keyword">for</span> crop <span class="keyword">in</span> crops])) <span class="comment"># returns a 4D tensor</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>])</span><br></pre></td></tr></table></figure>

<h4 id="torchvision-transforms-Pad-padding-fill-0-padding-mode-’constant’"><a href="#torchvision-transforms-Pad-padding-fill-0-padding-mode-’constant’" class="headerlink" title="torchvision.transforms.Pad(padding, fill=0, padding_mode=’constant’)"></a><code>torchvision.transforms.Pad</code>(<em>padding</em>, <em>fill=0</em>, <em>padding_mode=’constant’</em>)</h4><p>用给定的pad值对图像的4个sides进行填充</p>
<p>参数：padding: 用于确定每个border填充的数量. </p>
<p>​    如果只有一个int，对所有的边进行一样的填充数量</p>
<p>​    如果为长度为2的tuple，那么是对左右，上下分别指定</p>
<p>​    如果长度为4的tuple，那么是对左、上，右、下的边分别指定 </p>
<p>fill: 当mode为constfill时的填充值。默认为0，如果是一个长度为3的tuple是，分别为RGB值</p>
<p>padding_mode:padding的类型</p>
<p>​    constant，常数填充</p>
<p>​    edge：用edge上的值进行填充</p>
<p>​    reflect：pads with reflection of image without repeating the last value on the edge</p>
<p>​    symmeic：pads with reflection of image repeating the last value on the edge</p>
<h4 id="torchvision-transforms-Grayscale-num-output-channels-1"><a href="#torchvision-transforms-Grayscale-num-output-channels-1" class="headerlink" title="torchvision.transforms.Grayscale(num_output_channels=1)"></a><code>torchvision.transforms.Grayscale</code>(<em>num_output_channels=1</em>)</h4><p>将image转为灰度图</p>
<p>参数：<strong>num_output_channels</strong> ，默认为1，也可以为3, 是想要输出图像的channel的个数。</p>
<p>输出：输入的灰度版本。如果nums为1，那么返回的image是单channel，如果是3，返回的image的三个r、g、b三个通道相等。</p>
<p>输出的type：PIL image</p>
<h4 id="torchvision-transforms-Resize-size-interpolation-2"><a href="#torchvision-transforms-Resize-size-interpolation-2" class="headerlink" title="torchvision.transforms.Resize(size, interpolation=2)"></a><code>torchvision.transforms.Resize</code>(<em>size</em>, <em>interpolation=2</em>)</h4><p>将输入的PILimage的大小resize到给定的大小</p>
<p>参数：<strong>size</strong> (<em>sequence</em> <em>or</em> int)期望的输出。如果size是int，那么短的边会匹配到这个数字。ie，如果height&gt;height, 那么image会被缩放为(size*height/width, size). 如果size为sequence，那么大小会被匹配到给定的（h,w）。</p>
<p><strong>interpolation</strong>: 插值的方法，默认为PIL.Image.BILINEAR</p>
<h2 id="Transforms-on-torch-Tensor"><a href="#Transforms-on-torch-Tensor" class="headerlink" title="Transforms on torch.*Tensor"></a>Transforms on torch.*Tensor</h2><h4 id="torchvision-transforms-Normalize-mean-std-inplace-False"><a href="#torchvision-transforms-Normalize-mean-std-inplace-False" class="headerlink" title="torchvision.transforms.Normalize(mean, std, inplace=False)"></a><code>torchvision.transforms.</code>Normalize(<em>mean</em>, <em>std</em>, <em>inplace=False</em>)</h4><p>归一化给定的mean，std来归一化一张tensor image。对于每一个channel进行<br>$$<br>\frac{（input[channel - mean[channel]）}{std[channel]}<br>$$<br>参数：mean：每个channel的均值</p>
<p>std: 每个channel的std值</p>
<p>返回：normalized Tensor image</p>
<p>返回类型：Tensor</p>
<p><strong>Note</strong>：不是就地改变输入Tensor</p>
<h2 id="Conversion-Transforms"><a href="#Conversion-Transforms" class="headerlink" title="Conversion Transforms"></a>Conversion Transforms</h2><h4 id="torchvision-transforms-ToPILImage-mode-None"><a href="#torchvision-transforms-ToPILImage-mode-None" class="headerlink" title="torchvision.transforms.ToPILImage(mode=None)"></a><code>torchvision.transforms.ToPILImage</code>(<em>mode=None</em>)</h4><p>将Tensor或者ndarray转换为PILimage</p>
<p>参数：mode:</p>
<p>如果mode没给定：</p>
<p>​    如果输入为4channel，那么默认为RGBA</p>
<p>​    如果输入为3channel，那么默认为RGB</p>
<p>​    如果输入为2channel，那么默认为LA</p>
<p>​    如果输入为1 channel，那么由mode参数确定</p>
<h4 id="torchvision-transforms-ToTensor"><a href="#torchvision-transforms-ToTensor" class="headerlink" title="torchvision.transforms.ToTensor"></a><code>torchvision.transforms.ToTensor</code></h4><p>将PIL image 或者ndarray转换为Tensor</p>
<p>将值范围为【0，255】的PIL image或者ndarray（H/<em>W/</em>C）转换为FloatTensor(C,H,W)并且值范围为【0.0，1.0】，如果the PIL Image属于 one of the modes (L, LA, P, I, F, RGB, YCbCr, RGBA, CMYK, 1) 或者 the numpy.ndarray has dtype = np.uint8</p>
<p>其他的，tensors不会进行缩放</p>
<h4 id="FiveCrop和TenCrop"><a href="#FiveCrop和TenCrop" class="headerlink" title="FiveCrop和TenCrop"></a>FiveCrop和TenCrop</h4><p>这两种操作之后,一张图变成五张,一张图变成十张,那么在训练或者测试的时候怎么避免和标签混淆呢<br>思路是,这多个图拥有相同的标签,假如是分类任务,就可以使用交叉熵进行,然后求10张图的平均</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">transform = Compose([</span><br><span class="line">    TenCrop(size), <span class="comment"># this is a list of PIL Images</span></span><br><span class="line">    Lambda(<span class="keyword">lambda</span> crops: torch.stack([ToTensor()(crop) <span class="keyword">for</span> crop <span class="keyword">in</span> crops])) <span class="comment"># returns a 4D tensor</span></span><br><span class="line">])</span><br><span class="line"></span><br><span class="line"><span class="comment">#In your test loop you can do the following:</span></span><br><span class="line">input, target = batch <span class="comment"># input is a 5d tensor, target is 2d</span></span><br><span class="line">bs, ncrops, c, h, w = input.size()</span><br><span class="line">result = model(input.view(<span class="number">-1</span>, c, h, w)) <span class="comment"># fuse batch size and ncrops</span></span><br><span class="line"></span><br><span class="line">result_avg = result.view(bs, ncrops, <span class="number">-1</span>).mean(<span class="number">1</span>) <span class="comment"># avg over crops</span></span><br></pre></td></tr></table></figure>


      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2019/07/02/TorchVision-Image-Transforms/" data-id="cjxlw7772001t5gulgvozmiky" class="article-share-link">分享</a>
      
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/pytorch/">pytorch</a></li></ul>

    </footer>
  </div>
  
</article>
 


  
    <article id="post-长尾分布特征的处理" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2019/07/02/长尾分布特征的处理/" class="article-date">
  <time datetime="2019-07-02T14:07:00.000Z" itemprop="datePublished">2019-07-02</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/machine-learning/">machine learning</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2019/07/02/长尾分布特征的处理/">长尾分布特征的处理</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <!-- Table of Contents -->
        
        <p>对特征进行log处理</p>
<p><img src="/images/assets/1557631665906.png" alt="1557631665906"></p>
<p>log后</p>
<p><img src="/images/assets/1557631687832.png" alt="1557631687832"></p>
<p>在kaggle比赛中，不仅可以对特征进行这样的log矫正的，对目标值也可以进行这样的矫正。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2019/07/02/长尾分布特征的处理/" data-id="cjxlw77ab00285guluwbm71sw" class="article-share-link">分享</a>
      
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/kaggle/">kaggle</a></li></ul>

    </footer>
  </div>
  
</article>
 


  
    <article id="post-Pytorch加载和读取模型" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2019/07/02/Pytorch加载和读取模型/" class="article-date">
  <time datetime="2019-07-02T14:05:45.000Z" itemprop="datePublished">2019-07-02</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/deep-learning/">deep learning</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2019/07/02/Pytorch加载和读取模型/">Pytorch加载和读取模型</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <!-- Table of Contents -->
        
        <p>首先看下有关的函数：</p>
<ol>
<li>torch.save: 将一个文件保存到硬盘上，内部是用了pickle库</li>
<li>troch.load：用的pickle的unpicking方法将存储在硬盘上的object读取到内存中</li>
<li>torch.nn.Module.load_state_dict：从一个state_dict中加载一个模型的参数</li>
</ol>
<p>什么是state_dict:</p>
<p>pytorch中的每个module的可学习的参数：如权重和bias等都在module.parameters()里面。</p>
<p>一个state_dict简单来说就是一个字典object，可以把每一层映射到他的参数上去。可学习参数以及register buffer(bn)已经优化器都有state_dict。因为state_dict是python字典对象，因此很简单就可以保存，修改。</p>
<p>下面是读取模型state_dict的例子：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> param_tensor <span class="keyword">in</span> model.state_dict():</span><br><span class="line">    print(param_tensor, <span class="string">"\t"</span>, model.state_dict()[param_tensor].size())</span><br></pre></td></tr></table></figure>

<h2 id="两种方法"><a href="#两种方法" class="headerlink" title="两种方法"></a>两种方法</h2><p>回到正题，有两种方法可以保存和读取模型。</p>
<p>第一种是通过模型的state_dict来进行读取和保存。特别是读取的时候，首先得新建一个模型object，然后加载参数。</p>
<p><strong>Save:</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.save(model.state_dict(), PATH)</span><br></pre></td></tr></table></figure>

<p><strong>Load:</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">model = TheModelClass(*args, **kwargs)</span><br><span class="line">model.load_state_dict(torch.load(PATH))</span><br><span class="line">model.eval()</span><br></pre></td></tr></table></figure>

<p>第二种方法之别保存和加载整个模型：</p>
<p><strong>Save:</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.save(model, PATH)</span><br></pre></td></tr></table></figure>

<p><strong>Load:</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Model class must be defined somewhere</span></span><br><span class="line">model = torch.load(PATH)</span><br><span class="line">model.eval()</span><br></pre></td></tr></table></figure>

<p>这种方法的缺点是序列化数据绑定到特定类以及保存模型时使用的确切目录结构。这是因为pickle不保存模型类本身。相反，它会保存包含类的文件的路径，该文件在加载时使用。因此，当您在其他项目中或在重构之后使用时，您的代码可能会以各种方式中断。</p>
<h2 id="保存checkpoint"><a href="#保存checkpoint" class="headerlink" title="保存checkpoint"></a>保存checkpoint</h2><p>可以保存checkpoint用于后续的推理和重新训练。和单独保存模型的参数不同，优化器的参数也会被保存，以便于后续的训练。</p>
<h3 id="Save"><a href="#Save" class="headerlink" title="Save:"></a>Save:</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">torch.save(&#123;</span><br><span class="line">            &apos;epoch&apos;: epoch,</span><br><span class="line">            &apos;model_state_dict&apos;: model.state_dict(),</span><br><span class="line">            &apos;optimizer_state_dict&apos;: optimizer.state_dict(),</span><br><span class="line">            &apos;loss&apos;: loss,</span><br><span class="line">            ...</span><br><span class="line">            &#125;, PATH)</span><br></pre></td></tr></table></figure>

<h3 id="Load"><a href="#Load" class="headerlink" title="Load:"></a>Load:</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">model = TheModelClass(*args, **kwargs)</span><br><span class="line">optimizer = TheOptimizerClass(*args, **kwargs)</span><br><span class="line"></span><br><span class="line">checkpoint = torch.load(PATH)</span><br><span class="line">model.load_state_dict(checkpoint[<span class="string">'model_state_dict'</span>])</span><br><span class="line">optimizer.load_state_dict(checkpoint[<span class="string">'optimizer_state_dict'</span>])</span><br><span class="line">epoch = checkpoint[<span class="string">'epoch'</span>]</span><br><span class="line">loss = checkpoint[<span class="string">'loss'</span>]</span><br><span class="line"></span><br><span class="line">model.eval()</span><br><span class="line"><span class="comment"># - or -</span></span><br><span class="line">model.train()</span><br></pre></td></tr></table></figure>

<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><p><a href="https://pytorch.org/tutorials/beginner/saving_loading_models.html" target="_blank" rel="noopener">https://pytorch.org/tutorials/beginner/saving_loading_models.html</a></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2019/07/02/Pytorch加载和读取模型/" data-id="cjxlw771y000p5gulfw9d3jbq" class="article-share-link">分享</a>
      
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/pytorch/">pytorch</a></li></ul>

    </footer>
  </div>
  
</article>
 


  
    <article id="post-Pytorch-TensorboardX-可视化" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2019/07/02/Pytorch-TensorboardX-可视化/" class="article-date">
  <time datetime="2019-07-02T14:04:29.000Z" itemprop="datePublished">2019-07-02</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/deeplearning/">deeplearning</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2019/07/02/Pytorch-TensorboardX-可视化/">Pytorch TensorboardX 可视化</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <!-- Table of Contents -->
        
        <h2 id="安装tensorboard"><a href="#安装tensorboard" class="headerlink" title="安装tensorboard"></a>安装tensorboard</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">pip install tensorboardX</span><br><span class="line">pip install tensorflow</span><br></pre></td></tr></table></figure>

<h2 id="使用"><a href="#使用" class="headerlink" title="使用"></a>使用</h2><h4 id="引入并创建一个SummaryWriter"><a href="#引入并创建一个SummaryWriter" class="headerlink" title="引入并创建一个SummaryWriter"></a>引入并创建一个SummaryWriter</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">from tensorboardX import SummaryWriter</span><br><span class="line">writer = SummaryWriter(&apos;./runs/dogcat1&apos;)  //log_dir is ./run/dogcat</span><br><span class="line">//need close</span><br><span class="line">writer.close()</span><br></pre></td></tr></table></figure>

<p>logdir参数要是不指定的话，会自动在生成run文件夹。另外还有一个comment参数，用于指定文件名称。</p>
<h4 id="画loss曲线："><a href="#画loss曲线：" class="headerlink" title="画loss曲线："></a>画loss曲线：</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">writer.add_scalar(&apos;loss&apos;,loss, epoch)</span><br></pre></td></tr></table></figure>

<p>第一个参数为保存参数的名称，第二个参数为Y轴的值，第三个参数为X轴的值</p>
<p>运行该代码后，在log_dir下运行：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tensorboard --logdir log_dir  //log_dir 为具体的文件夹</span><br></pre></td></tr></table></figure>

<p>具体为：</p>
<p><img src="/images/assets/1555679643005.png" alt="1555679643005"></p>
<p>结果为：</p>
<p><img src="/images/assets/1555681461022.png" alt="1555681461022"></p>
<h4 id="画激活情况"><a href="#画激活情况" class="headerlink" title="画激活情况"></a>画激活情况</h4><p>用于检查深层网络里面的层激活和权值分布情况，避免梯度消失等。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">for name, param in net.named_parameters():</span><br><span class="line">	writer.add_histogram(</span><br><span class="line">		name, param.cpu().clone().data.numpy(), epoch_index)</span><br></pre></td></tr></table></figure>

<p>需要注意的是，如果tensor在gpu需要将其转换到cpu中。</p>
<p>结果为：</p>
<p><img src="/images/assets/1555682223014.png" alt="1555682223014"></p>
<h4 id="画网络结构图"><a href="#画网络结构图" class="headerlink" title="画网络结构图"></a>画网络结构图</h4><p>首先先对某个model进行实例化，如net。然后定义一个输入：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">input = torch.rand(dim1,dim2,dim3,dim4)</span><br><span class="line"></span><br><span class="line">net = LeNet()</span><br><span class="line">writer.add_graph(net, input)</span><br></pre></td></tr></table></figure>

<p>同样的，需要注意net要在cpu中。</p>
<p>效果如下：</p>
<p><img src="/images/assets/1555682403877.png" alt="1555682403877"></p>
<h4 id="显示图片"><a href="#显示图片" class="headerlink" title="显示图片"></a>显示图片</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">writer.add_image(&apos;name&apos;,image_object)</span><br></pre></td></tr></table></figure>

<h4 id="Projection"><a href="#Projection" class="headerlink" title="Projection"></a>Projection</h4><p>使用PCA，T-SNE等方法将高位向量投影到三维坐标系。默认使用PCA，也可以选择T-SNE</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">writer.add_embedding(mat, metadata=None, label_img=None, global_step=None, tag=&apos;default&apos;, metadata_header=None）</span><br></pre></td></tr></table></figure>

<ul>
<li><strong>mat</strong> (<a href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" target="_blank" rel="noopener"><em>torch.Tensor</em></a> <em>or</em> <em>numpy.array</em>) – A matrix which each row is the feature vector of the data point</li>
<li><strong>metadata</strong> (<a href="https://docs.python.org/3/library/stdtypes.html#list" target="_blank" rel="noopener"><em>list</em></a>) – A list of labels, each element will be convert to string</li>
<li><strong>label_img</strong> (<a href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" target="_blank" rel="noopener"><em>torch.Tensor</em></a>) – Images correspond to each data point</li>
<li><strong>global_step</strong> (<a href="https://docs.python.org/3/library/functions.html#int" target="_blank" rel="noopener"><em>int</em></a>) – Global step value to record</li>
<li><strong>tag</strong> (<em>string</em>) – Name for the embedding</li>
</ul>
<h4 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h4><p><a href="https://tensorboardx.readthedocs.io/en/latest/tensorboard.html" target="_blank" rel="noopener">https://tensorboardx.readthedocs.io/en/latest/tensorboard.html</a></p>
<p><a href="http://www.pianshen.com/article/3479170564/" target="_blank" rel="noopener">http://www.pianshen.com/article/3479170564/</a></p>
<p><a href="https://github.com/pytorch/pytorch/issues/2731" target="_blank" rel="noopener">https://github.com/pytorch/pytorch/issues/2731</a></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2019/07/02/Pytorch-TensorboardX-可视化/" data-id="cjxlw771h000k5gul2583qeua" class="article-share-link">分享</a>
      
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/cnn/">cnn</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/pytorch/">pytorch</a></li></ul>

    </footer>
  </div>
  
</article>
 


  
    <article id="post-Normalize的作用" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2019/07/02/Normalize的作用/" class="article-date">
  <time datetime="2019-07-02T14:00:04.000Z" itemprop="datePublished">2019-07-02</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/deep-learning/">deep learning</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2019/07/02/Normalize的作用/">Normalize的作用</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <!-- Table of Contents -->
        
        <p>normalize的最主要的一个作用是将数据中的不同的特征缩放到同一个量纲上（或者可以说无量纲化）。比如果说有一个特征值的范围是[0,1]另一个特征的范围是[0,1000],那么优化算法（尤其是基于梯度的优化方法）在更新的时候尤其会重视特征值大的特征，而忽视特征值小的特征。为了避免这个问题就需要normalization了，把所有的特征放在一个量纲上。</p>
<p><img src="/images/assets/743682-20151108152327539-2039269197.png" alt="img"></p>
<h2 id="常用的normalization的方法"><a href="#常用的normalization的方法" class="headerlink" title="常用的normalization的方法"></a>常用的normalization的方法</h2><p>主要有两种方法，min-max normalization 和 Z-score normalization。</p>
<h3 id="min-max-normalization"><a href="#min-max-normalization" class="headerlink" title="min-max normalization"></a>min-max normalization</h3><p>$$<br>x_{minmax} = \frac{x - x_{min}}{x_{max} - x_{min}}<br>$$</p>
<p>主要有两个缺陷:</p>
<ol>
<li>新加入的数据会导致$x_{max}$和$x_{min}$ 会发生变化，需要重新定义</li>
<li>异常值会极大地影响minmax的表现</li>
<li>minmax不适用于长尾分布</li>
</ol>
<p>比较适合于min和max固定的任务，比如图像像素归一化。</p>
<h3 id="Z-score-normalization"><a href="#Z-score-normalization" class="headerlink" title="Z-score normalization"></a>Z-score normalization</h3><p>$$<br>x_{zscore} = \frac{x - min(x)}{stdev(x)}<br>$$</p>
<p>z-score的问题没有min-max多，对异常值也较为鲁棒性。且经过处理的数据会较为贴近正态分布（不是变为），大多数的数据会聚集在0附近，方差为1.</p>
<blockquote>
<p>Caveat:* it is a common misconception that <em>standardized scores</em> such as <em>z-scores</em> alter the shape of a distribution; in particular, be aware that a <em>z</em>-scores cannot magically make a non-normal variable normal.</p>
</blockquote>
<p>其他的还有logistic，lognormal，TanH等，见</p>
<h2 id="Normalizing"><a href="#Normalizing" class="headerlink" title="Normalizing"></a>Normalizing</h2><p>和上面不同的方式，是直接对样本进行单位化，即<br>$$<br>x = \frac{x}{norm(x)}<br>$$<br>不同的norm会有不同的结果，常见的是L2 norm</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2019/07/02/Normalize的作用/" data-id="cjxlw770n00095gul13nuvddc" class="article-share-link">分享</a>
      
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/normalize/">normalize</a></li></ul>

    </footer>
  </div>
  
</article>
 


  
    <article id="post-PyTorch-weight-decay（转）" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2019/07/02/PyTorch-weight-decay（转）/" class="article-date">
  <time datetime="2019-07-02T13:58:33.000Z" itemprop="datePublished">2019-07-02</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/deep-learning/">deep learning</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2019/07/02/PyTorch-weight-decay（转）/">PyTorch weight decay（转）</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <!-- Table of Contents -->
        
        <p>torch.optim 中实现了很多优化器，只需要指定优化器的权重衰减即可：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">optimizer = optim.SGD(model.parameters(), lr = <span class="number">0.01</span>, momentum=<span class="number">0.9</span>,weight_decay=<span class="number">1e-5</span>)</span><br></pre></td></tr></table></figure>

<p>优化器同时还支持per-parameter options操作，就是对每一个参数进行特定的制定，以满足更为细致的要求。此时，传入优化器的是可迭代的字典，字典中必须有params的key，用于指定特定优化变量，而其他key需要匹配优化器本身的设置。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">optim.SGD([</span><br><span class="line">                &#123;&apos;params&apos;: model.base.parameters()&#125;,</span><br><span class="line">                &#123;&apos;params&apos;: model.classifier.parameters(), &apos;lr&apos;: 1e-3&#125;</span><br><span class="line">            ], lr=1e-2, momentum=0.9)</span><br></pre></td></tr></table></figure>

<p>可以灵活给每个子模块设置不同的学习率，权值衰减和momentum。也可以给权值设定权值衰减，而不作用于偏置：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">weight_p, bias_p = [],[]</span><br><span class="line">for name, p in model.named_parameters():</span><br><span class="line">  if &apos;bias&apos; in name:</span><br><span class="line">     bias_p += [p]</span><br><span class="line">   else:</span><br><span class="line">     weight_p += [p]</span><br><span class="line"># 这里的model中每个参数的名字都是系统自动命名的，只要是权值都是带有weight，偏置都带有bias，</span><br><span class="line"></span><br><span class="line">optim.SGD([</span><br><span class="line">          &#123;&apos;params&apos;: weight_p, &apos;weight_decay&apos;:1e-5&#125;,</span><br><span class="line">          &#123;&apos;params&apos;: bias_p, &apos;weight_decay&apos;:0&#125;</span><br><span class="line">          ], lr=1e-2, momentum=0.9)</span><br></pre></td></tr></table></figure>

<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><p><a href="https://blog.csdn.net/LoseInVain/article/details/81708474" target="_blank" rel="noopener">https://blog.csdn.net/LoseInVain/article/details/81708474</a> </p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2019/07/02/PyTorch-weight-decay（转）/" data-id="cjxlw771d000h5gulvcsgdywz" class="article-share-link">分享</a>
      
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/L2-Norm/">L2 Norm</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/weight-decay/">weight decay</a></li></ul>

    </footer>
  </div>
  
</article>
 


  
    <article id="post-Softmax-and-Logsoftmax-in-Pytorch" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2019/07/02/Softmax-and-Logsoftmax-in-Pytorch/" class="article-date">
  <time datetime="2019-07-02T13:57:25.000Z" itemprop="datePublished">2019-07-02</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/deep-learning/">deep learning</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2019/07/02/Softmax-and-Logsoftmax-in-Pytorch/">Softmax and Logsoftmax in Pytorch</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <!-- Table of Contents -->
        
        <p>Output layer and criterion options (all are equivalent, 1 is most popular) :</p>
<ol>
<li>Linear + LogSoftMax + ClassNLLCriterion</li>
<li>Linear + SoftMax + Log + ClassNLLCriterion</li>
<li>Linear + CrossEntropyCriterion</li>
</ol>
<p>It should be noted that <strong>CrossEntropyLoss includes a softmax operation.</strong></p>
<p>softmax with log-likelihood cost can be more fast compared with softmax with MSELoss.</p>
<p>The <strong>log-likelihood loss</strong> is<br>$$<br>C = - \Sigma_k y_klog(a_k)<br>$$<br>where $a_k$ is the output of a neuron, and $y_k$ is the truth.</p>
<p>The <strong>cross-entropy loss</strong> is<br>$$<br>C_{CE} = -\Sigma_k \ y_klog(a_k) + (1-y_k)log(1-a_k)<br>$$<br>And what’s the logsoftmax?<br>$$<br>Applies \ the \ <code>\log(\text{Softmax}(x))</code> function \  to \ an \ n-dimensional<br>    \ input \ Tensor. \ The \ LogSoftmax \ formulation \ can \ be \ simplified \ as:\</p>
<pre><code>\text{LogSoftmax}(x_{i}) = \log\left(\frac{\exp(x_i) }{ \sum_j \exp(x_j)} \right)</code></pre><p>$$<br>what’s more, it’s actually realized in nn.functional<br>$$<br>While \ mathematically \ equivalent \  to \   log(softmax(x)), \  doing \  these \   two \ operations \  separately  \ is  \ slower,  \  and  \ numerically  \ unstable.\ This \  function \<br>    \  uses \  an \  alternative \  formulation \  to  \ compute  \ the  \ output \  and  \ gradient  \ correctly.<br>$$<br>The <strong>NLLoss</strong> is:<br>$$<br>Loss \ = - w_nx_{n,y_n}<br>$$<br>where $w_n$ default is 1.</p>
<p>The <strong>BCELoss</strong> is a CrossEntropyLoss designed for binary classification. And it need a sigmoid function before useing the BCELoss. What’s more, <strong>BCEWithLogitsLoss</strong> includes the BCELoss and the sigmoid function.</p>
<h4 id="References"><a href="#References" class="headerlink" title="References"></a>References</h4><p><a href="https://github.com/torch/nn/issues/357" target="_blank" rel="noopener">https://github.com/torch/nn/issues/357</a></p>
<p><a href="https://pytorch.org/docs/stable/_modules/torch/nn/functional.html#log_softmax" target="_blank" rel="noopener">https://pytorch.org/docs/stable/_modules/torch/nn/functional.html#log_softmax</a></p>
<p><a href="https://pytorch.org/docs/stable/nn.html?highlight=log_softmax#torch.nn.functional.log_softmax" target="_blank" rel="noopener">https://pytorch.org/docs/stable/nn.html?highlight=log_softmax#torch.nn.functional.log_softmax</a></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2019/07/02/Softmax-and-Logsoftmax-in-Pytorch/" data-id="cjxlw7770001s5gulfgggf7hq" class="article-share-link">分享</a>
      
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/cnn/">cnn</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/cross-entropy/">cross-entropy</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/softmax/">softmax</a></li></ul>

    </footer>
  </div>
  
</article>
 


  
    <article id="post-Pytorch-SGDR" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2019/07/02/Pytorch-SGDR/" class="article-date">
  <time datetime="2019-07-02T13:55:31.000Z" itemprop="datePublished">2019-07-02</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/deep-learning/">deep learning</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2019/07/02/Pytorch-SGDR/">Pytorch SGDR</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <!-- Table of Contents -->
        
        <h2 id="SGDR-paper"><a href="#SGDR-paper" class="headerlink" title="SGDR paper"></a>SGDR paper</h2><p>学习率schedule最常见的方法是用一个lr，然后每隔几个epoch除以一个数来减少lr。如下图中的蓝色⚪线和红色</p>
<p>的方块线。</p>
<p><img src="/images/assets/1557729884981.png" alt="1557729884981"></p>
<p>这篇论文所提出的方法是SGD的warm restart版本，即在每次restart，lr都被设置到初始值，但是他的上一次restart到下一次restart之间的距离（schedule）会增加。作者的经验表明，他的这个方法可以比其他的方法快2~4倍达到一个好的效果或者更好的效果。</p>
<p>warm started run SGD T_i 次，其中i是run的index。重要的是，重启不是从头开始执行，而是通过提高学习速率ηt来模拟，而旧的xt值用作初始解决方案</p>
<p>在第i次run，lr decay 是对每个batch用cosine annealing.</p>
<p><img src="E:%5C%E5%88%98%E5%BF%97%E4%BC%9F%E7%9A%84%E6%96%87%E4%BB%B6%5C%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%5Cpytorch%5Cassets%5C1557730343579.png" alt="1557730343579"><br>$$<br>\eta_{min} 和 \eta_{max}是学习率的范围。 \<br>T_{cur}是距离上次restart所经过的epoch的数量。T_{cur}是每个batch增加，他可以是小数。 \<br>当t=0\ and\ T_{cur} = 0时，T_{cur}=T_{max} \<br>当T_{cur}=T_{max}时， cos 函数会输出-1.因此，\eta_t = \eta_{min}^i</p>
<p>$$<br>图1的绿色线、黑色线和灰色线显示了lr的变化过程。分别固定了$T_i$为50，100，200.</p>
<p>SGDR更进一步选了这么一方法，首先开始的时候$T_i$很小，然后在每次restart都通过乘上一个 $T_{mult}$的因此来提高。例如图一中的暗绿和粉色线。</p>
<h2 id="SGDR-in-pytorch"><a href="#SGDR-in-pytorch" class="headerlink" title="SGDR in pytorch"></a>SGDR in pytorch</h2><p>pytorch只实现了CosineAnnealingLR，并没有实现restart部分。</p>
<p><code>torch.optim.lr_scheduler.CosineAnnealingLR</code>(<em>optimizer</em>, <em>T_max</em>, <em>eta_min=0</em>, <em>last_epoch=-1</em>)</p>
<p><img src="/images/assets/1557731465430.png" alt="1557731465430"></p>
<p>它的用法如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">model = nn.Linear(<span class="number">10</span>, <span class="number">2</span>)</span><br><span class="line">optimizer = optim.SGD(model.parameters(), lr=<span class="number">1.</span>)</span><br><span class="line">steps = <span class="number">10</span></span><br><span class="line">scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, steps)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> range(<span class="number">5</span>):</span><br><span class="line">    <span class="keyword">for</span> idx <span class="keyword">in</span> range(steps):</span><br><span class="line">        scheduler.step()</span><br><span class="line">        print(scheduler.get_lr())</span><br></pre></td></tr></table></figure>

<p>实际上，可以通过下面的方式来实现SGDR</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">model = nn.Linear(<span class="number">10</span>, <span class="number">2</span>)</span><br><span class="line">optimizer = optim.SGD(model.parameters(), lr=<span class="number">1.</span>)</span><br><span class="line">steps = <span class="number">10</span></span><br><span class="line">scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, steps)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> range(<span class="number">5</span>):</span><br><span class="line">    <span class="keyword">for</span> idx <span class="keyword">in</span> range(steps):</span><br><span class="line">        scheduler.step()</span><br><span class="line">        print(scheduler.get_lr())</span><br><span class="line">    </span><br><span class="line">    print(<span class="string">'Reset scheduler'</span>)</span><br><span class="line">    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, steps)</span><br></pre></td></tr></table></figure>

<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><p><a href="https://discuss.pytorch.org/t/how-to-implement-torch-optim-lr-scheduler-cosineannealinglr/28797/18" target="_blank" rel="noopener">https://discuss.pytorch.org/t/how-to-implement-torch-optim-lr-scheduler-cosineannealinglr/28797/18</a></p>
<p><a href="https://pytorch.org/docs/master/optim.html#torch.optim.lr_scheduler.CosineAnnealingLR" target="_blank" rel="noopener">https://pytorch.org/docs/master/optim.html#torch.optim.lr_scheduler.CosineAnnealingLR</a></p>
<p><a href="https://arxiv.org/pdf/1608.03983.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1608.03983.pdf</a></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2019/07/02/Pytorch-SGDR/" data-id="cjxlw7713000d5gul2d6h80uc" class="article-share-link">分享</a>
      
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/cnn/">cnn</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/pytorch/">pytorch</a></li></ul>

    </footer>
  </div>
  
</article>
 


  
    <article id="post-PIL-使用" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2019/07/02/PIL-使用/" class="article-date">
  <time datetime="2019-07-02T13:53:55.000Z" itemprop="datePublished">2019-07-02</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/编程/">编程</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2019/07/02/PIL-使用/">PIL 使用</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <!-- Table of Contents -->
        
        <p>Pillow 是PIL全称，是一个python图像处理库，由Fredrik Lundh and Contributors创建的。</p>
<h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h2><figure class="highlight plain"><figcaption><span>basic</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ pip install Pillow</span><br></pre></td></tr></table></figure>

<p>基本上安装python和pip就可以安装pil。</p>
<h2 id="入门教程"><a href="#入门教程" class="headerlink" title="入门教程"></a>入门教程</h2><h3 id="Image-class"><a href="#Image-class" class="headerlink" title="Image class"></a>Image class</h3><p>PIL中最重要的类是<strong>Image</strong>，定义在PIL 底下的Image中。可以通过以下方式来创建一个<strong>Image</strong>类对象：</p>
<ul>
<li>通过打开一个图片文件来创建</li>
<li>通过处理其他的图片</li>
<li>从头创建图片</li>
</ul>
<p>从图片文件中打开文件的：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line">im = Image.open(<span class="string">'pic.png'</span>)</span><br></pre></td></tr></table></figure>

<p>如果成功，函数会返回一个Image对象。可以通过检查它的属性来查看它的内容：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(im.format, im.size, im.mode)</span><br></pre></td></tr></table></figure>

<p>其中，</p>
<ul>
<li>im.format是该图片的来源，如果不是来自图像文件，则会使None</li>
<li>im.size是图片的大小，是一个二维数组，单位是pixel</li>
<li>im.mode 是图片的显示模式，定义了图片的色带个数和名字；或像素的类型和深度；常见的模式有“L”是灰度图，“RGB”是真彩图片，“CMYK”是预印图片。</li>
</ul>
<p>如果文件不能打开，则会返回一个<strong>IOError</strong>异常。</p>
<p>图片的显示：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">im.show()</span><br></pre></td></tr></table></figure>

<p>图片的保存：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">im.save(<span class="string">"..."</span>)</span><br></pre></td></tr></table></figure>

<p>其他的图像打开方式：</p>
<h5 id="从打开的文件中读取："><a href="#从打开的文件中读取：" class="headerlink" title="从打开的文件中读取："></a>从打开的文件中读取：</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">with</span> open(<span class="string">"hopper.ppm"</span>, <span class="string">"rb"</span>) <span class="keyword">as</span> fp:</span><br><span class="line">    im = Image.open(fp)</span><br></pre></td></tr></table></figure>

<h5 id="从string中读取："><a href="#从string中读取：" class="headerlink" title="从string中读取："></a>从string中读取：</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> StringIO</span><br><span class="line"></span><br><span class="line">im = Image.open(StringIO.StringIO(buffer))</span><br></pre></td></tr></table></figure>

<h5 id="从tar文件中读取"><a href="#从tar文件中读取" class="headerlink" title="从tar文件中读取"></a>从tar文件中读取</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image, TarIO</span><br><span class="line"></span><br><span class="line">fp = TarIO.TarIO(<span class="string">"Tests/images/hopper.tar"</span>, <span class="string">"hopper.jpg"</span>)</span><br><span class="line">im = Image.open(fp)</span><br></pre></td></tr></table></figure>

<h3 id="读写图片"><a href="#读写图片" class="headerlink" title="读写图片"></a>读写图片</h3><h4 id="将文件转换成JPEG"><a href="#将文件转换成JPEG" class="headerlink" title="将文件转换成JPEG"></a>将文件转换成JPEG</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os, sys</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> infile <span class="keyword">in</span> sys.argv[<span class="number">1</span>:]:</span><br><span class="line">    f, e = os.path.splitext(infile)</span><br><span class="line">    outfile = f + <span class="string">".jpg"</span></span><br><span class="line">    <span class="keyword">if</span> infile != outfile:</span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            Image.open(infile).save(outfile)</span><br><span class="line">        <span class="keyword">except</span> IOError:</span><br><span class="line">            print(<span class="string">"cannot convert"</span>, infile)</span><br></pre></td></tr></table></figure>

<p>思路是将文件打开，再保存到jpeg文件即可。需要注意，打开文件需要try except以防IOError</p>
<h4 id="创建JPEG文件的缩略图"><a href="#创建JPEG文件的缩略图" class="headerlink" title="创建JPEG文件的缩略图"></a>创建JPEG文件的缩略图</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os, sys</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"></span><br><span class="line">size = (<span class="number">128</span>, <span class="number">128</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> infile <span class="keyword">in</span> sys.argv[<span class="number">1</span>:]:</span><br><span class="line">    outfile = os.path.splitext(infile)[<span class="number">0</span>] + <span class="string">".thumbnail"</span></span><br><span class="line">    <span class="keyword">if</span> infile != outfile:</span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            im = Image.open(infile)</span><br><span class="line">            im.thumbnail(size)</span><br><span class="line">            im.save(outfile, <span class="string">"JPEG"</span>)</span><br><span class="line">        <span class="keyword">except</span> IOError:</span><br><span class="line">            print(<span class="string">"cannot create thumbnail for"</span>, infile)</span><br></pre></td></tr></table></figure>

<p>思路是使用自带的thumbnai函数。</p>
<h4 id="鉴定图片"><a href="#鉴定图片" class="headerlink" title="鉴定图片"></a>鉴定图片</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> print_function</span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> infile <span class="keyword">in</span> sys.argv[<span class="number">1</span>:]:</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        <span class="keyword">with</span> Image.open(infile) <span class="keyword">as</span> im:</span><br><span class="line">            print(infile, im.format, <span class="string">"%dx%d"</span> % im.size, im.mode)</span><br><span class="line">    <span class="keyword">except</span> IOError:</span><br><span class="line">        <span class="keyword">pass</span></span><br></pre></td></tr></table></figure>

<h4 id="剪切合并图片"><a href="#剪切合并图片" class="headerlink" title="剪切合并图片"></a>剪切合并图片</h4><p><strong>Image</strong> class可以通过crop()函数来提取局部区域图片。</p>
<h5 id="复制图像的一个长方形区域："><a href="#复制图像的一个长方形区域：" class="headerlink" title="复制图像的一个长方形区域："></a>复制图像的一个长方形区域：</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">box = (<span class="number">100</span>, <span class="number">100</span>, <span class="number">400</span>, <span class="number">400</span>)</span><br><span class="line">region = im.crop(box)</span><br></pre></td></tr></table></figure>

<p>box是一个四维tuple，定义了（左，上，右，下）。该库的坐标系是将左上角定义为原点（0，0），同时所采用的距离是pixel。</p>
<h5 id="处理长方形区域并paste回去"><a href="#处理长方形区域并paste回去" class="headerlink" title="处理长方形区域并paste回去"></a>处理长方形区域并paste回去</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">region = region.transpose(Image.ROTATE_180)</span><br><span class="line">im.paste(region, box)</span><br></pre></td></tr></table></figure>

<p>paste函数要求region和box需要一致。</p>
<h5 id="分离合并图像channel"><a href="#分离合并图像channel" class="headerlink" title="分离合并图像channel"></a>分离合并图像channel</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">r, g, b = im.split()</span><br><span class="line">im = Image.merge(<span class="string">"RGB"</span>, (b, g, r))</span><br></pre></td></tr></table></figure>

<h4 id="集合转换"><a href="#集合转换" class="headerlink" title="集合转换"></a>集合转换</h4><h5 id="图片resize和旋转"><a href="#图片resize和旋转" class="headerlink" title="图片resize和旋转"></a>图片resize和旋转</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">out = im.resize((<span class="number">128</span>, <span class="number">128</span>))</span><br><span class="line">out = im.rotate(<span class="number">45</span>) <span class="comment"># degrees counter-clockwise</span></span><br></pre></td></tr></table></figure>

<h5 id="图片翻转"><a href="#图片翻转" class="headerlink" title="图片翻转"></a>图片翻转</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">out = im.transpose(Image.FLIP_LEFT_RIGHT)</span><br><span class="line">out = im.transpose(Image.FLIP_TOP_BOTTOM)</span><br><span class="line">out = im.transpose(Image.ROTATE_90)</span><br><span class="line">out = im.transpose(Image.ROTATE_180)</span><br><span class="line">out = im.transpose(Image.ROTATE_270)</span><br></pre></td></tr></table></figure>

<h4 id="颜色转换"><a href="#颜色转换" class="headerlink" title="颜色转换"></a>颜色转换</h4><h5 id="不同图像mode转换"><a href="#不同图像mode转换" class="headerlink" title="不同图像mode转换"></a>不同图像mode转换</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line">im = Image.open(<span class="string">"hopper.ppm"</span>).convert(<span class="string">"L"</span>)</span><br></pre></td></tr></table></figure>

<h4 id="图像增强"><a href="#图像增强" class="headerlink" title="图像增强"></a>图像增强</h4><h5 id="过滤"><a href="#过滤" class="headerlink" title="过滤"></a>过滤</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> ImageFilter</span><br><span class="line">out = im.filter(ImageFilter.DETAIL)</span><br></pre></td></tr></table></figure>

<h5 id="点操作"><a href="#点操作" class="headerlink" title="点操作"></a>点操作</h5><p>用于操作图像的像素值。</p>
<h5 id="应用点操作"><a href="#应用点操作" class="headerlink" title="应用点操作"></a>应用点操作</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># multiply each pixel by 1.2</span></span><br><span class="line">out = im.point(<span class="keyword">lambda</span> i: i * <span class="number">1.2</span>)</span><br></pre></td></tr></table></figure>

<h5 id="处理单个通道"><a href="#处理单个通道" class="headerlink" title="处理单个通道"></a>处理单个通道</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># split the image into individual bands</span></span><br><span class="line">source = im.split()</span><br><span class="line"></span><br><span class="line">R, G, B = <span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># select regions where red is less than 100</span></span><br><span class="line">mask = source[R].point(<span class="keyword">lambda</span> i: i &lt; <span class="number">100</span> <span class="keyword">and</span> <span class="number">255</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># process the green band</span></span><br><span class="line">out = source[G].point(<span class="keyword">lambda</span> i: i * <span class="number">0.7</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># paste the processed band back, but only where red was &lt; 100</span></span><br><span class="line">source[G].paste(out, <span class="literal">None</span>, mask)</span><br><span class="line"></span><br><span class="line"><span class="comment"># build a new multiband image</span></span><br><span class="line">im = Image.merge(im.mode, source)</span><br></pre></td></tr></table></figure>

<h5 id="增强图片"><a href="#增强图片" class="headerlink" title="增强图片"></a>增强图片</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> ImageEnhance</span><br><span class="line"></span><br><span class="line">enh = ImageEnhance.Contrast(im)</span><br><span class="line">enh.enhance(<span class="number">1.3</span>).show(<span class="string">"30% more contrast"</span>)</span><br></pre></td></tr></table></figure>

<h3 id="图像序列"><a href="#图像序列" class="headerlink" title="图像序列"></a>图像序列</h3><p>PIL支持FLI、FLC、GIF等图像序列文件。</p>
<p>当使用图像序列文件，PIL会自动地打开序列中的第一帧。可以使用seek和tell方法来移动帧。</p>
<h4 id="读取序列"><a href="#读取序列" class="headerlink" title="读取序列"></a>读取序列</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"></span><br><span class="line">im = Image.open(<span class="string">"animation.gif"</span>)</span><br><span class="line">im.seek(<span class="number">1</span>) <span class="comment"># skip to the second frame</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    <span class="keyword">while</span> <span class="number">1</span>:</span><br><span class="line">        im.seek(im.tell()+<span class="number">1</span>)</span><br><span class="line">        <span class="comment"># do something to im</span></span><br><span class="line"><span class="keyword">except</span> EOFError:</span><br><span class="line">    <span class="keyword">pass</span> <span class="comment"># end of sequence</span></span><br></pre></td></tr></table></figure>

<p>在序列停止的时候，会返还一个EOFError。</p>
<h4 id="使用ImageSequen-Iterator-class"><a href="#使用ImageSequen-Iterator-class" class="headerlink" title="使用ImageSequen Iterator class"></a>使用ImageSequen Iterator class</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> ImageSequence</span><br><span class="line"><span class="keyword">for</span> frame <span class="keyword">in</span> ImageSequence.Iterator(im):</span><br><span class="line">    <span class="comment"># ...do something to frame...</span></span><br></pre></td></tr></table></figure>

<h3 id="Postscript-printing"><a href="#Postscript-printing" class="headerlink" title="Postscript printing"></a>Postscript printing</h3><p>用Postscript printers来打印图片文本和图像</p>
<h4 id="Drawing-Postscript"><a href="#Drawing-Postscript" class="headerlink" title="Drawing Postscript"></a>Drawing Postscript</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> PSDraw</span><br><span class="line"></span><br><span class="line">im = Image.open(<span class="string">"hopper.ppm"</span>)</span><br><span class="line">title = <span class="string">"hopper"</span></span><br><span class="line">box = (<span class="number">1</span>*<span class="number">72</span>, <span class="number">2</span>*<span class="number">72</span>, <span class="number">7</span>*<span class="number">72</span>, <span class="number">10</span>*<span class="number">72</span>) <span class="comment"># in points</span></span><br><span class="line"></span><br><span class="line">ps = PSDraw.PSDraw() <span class="comment"># default is sys.stdout</span></span><br><span class="line">ps.begin_document(title)</span><br><span class="line"></span><br><span class="line"><span class="comment"># draw the image (75 dpi)</span></span><br><span class="line">ps.image(box, im, <span class="number">75</span>)</span><br><span class="line">ps.rectangle(box)</span><br><span class="line"></span><br><span class="line"><span class="comment"># draw title</span></span><br><span class="line">ps.setfont(<span class="string">"HelveticaNarrow-Bold"</span>, <span class="number">36</span>)</span><br><span class="line">ps.text((<span class="number">3</span>*<span class="number">72</span>, <span class="number">4</span>*<span class="number">72</span>), title)</span><br><span class="line"></span><br><span class="line">ps.end_document()</span><br></pre></td></tr></table></figure>
      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2019/07/02/PIL-使用/" data-id="cjxlw770z000c5gulzckqhntq" class="article-share-link">分享</a>
      
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Pillow/">Pillow</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/pytorch/">pytorch</a></li></ul>

    </footer>
  </div>
  
</article>
 


  


  <nav id="page-nav">
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><a class="extend next" rel="next" href="/page/2/">下一页&raquo;</a>
  </nav>
</section>
           
    <aside id="sidebar">
  
    
  <div class="widget-wrap">
     
        <h3 class="follow-title ">Follow me</h3>
     
    <div class="widget follow">
      
              <a class="github" aria-hidden="true" href="https://github.com/liulin1995" target="_blank" title="Github"></a>
      
      
      
      
    </div>
  </div>


  
    
  
    
  <div class="widget-wrap">
    <h3 class="widget-title categories">分类</h3>
    <div class="widget" id="categories">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/deep-learning/">deep learning</a><span class="category-list-count">10</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/deeplearning/">deeplearning</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/machine-learning/">machine learning</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/编程/">编程</a><span class="category-list-count">2</span></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title tagcloud">标签云</h3>
    <div class="widget tagcloud">
      <a href="/tags/Cyclical-LR/" style="font-size: 14px;">Cyclical LR</a> <a href="/tags/L2-Norm/" style="font-size: 14px;">L2 Norm</a> <a href="/tags/Pillow/" style="font-size: 14px;">Pillow</a> <a href="/tags/cnn/" style="font-size: 21.33px;">cnn</a> <a href="/tags/cross-entropy/" style="font-size: 14px;">cross-entropy</a> <a href="/tags/ensemble/" style="font-size: 14px;">ensemble</a> <a href="/tags/github/" style="font-size: 14px;">github</a> <a href="/tags/kaggle/" style="font-size: 17.67px;">kaggle</a> <a href="/tags/normalize/" style="font-size: 14px;">normalize</a> <a href="/tags/pytorch/" style="font-size: 25px;">pytorch</a> <a href="/tags/softmax/" style="font-size: 14px;">softmax</a> <a href="/tags/transfer-learning/" style="font-size: 14px;">transfer learning</a> <a href="/tags/weight-decay/" style="font-size: 14px;">weight decay</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title recent-posts">最新文章</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2019/07/02/Cyclical-Learning-Rates-for-Training-Neural-Networks/">Cyclical Learning Rates for Training Neural Networks</a>
          </li>
        
          <li>
            <a href="/2019/07/02/TorchVision-Image-Transforms/">TorchVison Image Transforms</a>
          </li>
        
          <li>
            <a href="/2019/07/02/长尾分布特征的处理/">长尾分布特征的处理</a>
          </li>
        
          <li>
            <a href="/2019/07/02/Pytorch加载和读取模型/">Pytorch加载和读取模型</a>
          </li>
        
          <li>
            <a href="/2019/07/02/Pytorch-TensorboardX-可视化/">Pytorch TensorboardX 可视化</a>
          </li>
        
      </ul>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title archive">归档</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/07/">July 2019</a><span class="archive-list-count">16</span></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title tags">标签</h3>
    <div class="widget">
      <ul class="tag-list"><li class="tag-list-item"><a class="tag-list-link" href="/tags/Cyclical-LR/">Cyclical LR</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/L2-Norm/">L2 Norm</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Pillow/">Pillow</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/cnn/">cnn</a><span class="tag-list-count">5</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/cross-entropy/">cross-entropy</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/ensemble/">ensemble</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/github/">github</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/kaggle/">kaggle</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/normalize/">normalize</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/pytorch/">pytorch</a><span class="tag-list-count">10</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/softmax/">softmax</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/transfer-learning/">transfer learning</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/weight-decay/">weight decay</a><span class="tag-list-count">1</span></li></ul>
    </div>
  </div>


  
    
<div class="widget-wrap">
    <h3 class="widget-title">Links</h3>
    <div class="widget">
        <ul>
            
            <li>
                <a href="https://discuss.pytorch.org/">pytorch</a>
            </li>
            
        </ul>
    </div>
</div>

  
</aside>

      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-left">
      &copy; 2014 - 2019 John Doe&nbsp;|&nbsp;
      主题 <a href="https://github.com/giscafer/hexo-theme-cafe/" target="_blank">Cafe</a>
    </div>
     <div id="footer-right">
      联系方式&nbsp;|&nbsp;noemail.gmail.com
    </div>
  </div>
</footer>
 <script src="/jquery/jquery.min.js"></script>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">首页</a>
  
    <a href="/archives" class="mobile-nav-link">归档</a>
  
    <a href="/about" class="mobile-nav-link">关于</a>
  
    <a href="/categories" class="mobile-nav-link">类别</a>
  
</nav>
    <img class="back-to-top-btn" src="/images/fly-to-top.png"/>
<script>
// Elevator script included on the page, already.
window.onload = function() {
  var elevator = new Elevator({
    selector:'.back-to-top-btn',
    element: document.querySelector('.back-to-top-btn'),
    duration: 1000 // milliseconds
  });
}
</script>
      

  
    <script>
      var cloudTieConfig = {
        url: document.location.href, 
        sourceId: "",
        productKey: "e2fb4051c49842688ce669e634bc983f",
        target: "cloud-tie-wrapper"
      };
    </script>
    <script src="https://img1.ws.126.net/f2e/tie/yun/sdk/loader.js"></script>
    

  







<!-- author:forvoid begin -->
<!-- author:forvoid begin -->

<!-- author:forvoid end -->

<!-- author:forvoid end -->


  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      })
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      })
    </script>
    <script type="text/javascript" src="https://cdn.rawgit.com/mathjax/MathJax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
  


 <script src="/js/is.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/script.js"></script>
<script src="/js/elevator.js"></script>
  </div>
</body>
</html>